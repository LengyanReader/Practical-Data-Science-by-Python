{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSSL Exam - 2021-02-17\n",
    "This notebook contains the four exam problems.\n",
    "\n",
    "* Please write your solutions directly in the notebook.\n",
    "\n",
    "* Your submission should consist of: (i) an executable notebook (.ipynb file), **and** a pdf printout of the same notebook. Please make sure that all your answers are visible in the pdf file. To generate the pdf file from the notebook, you can either go to _File->Download as->PDF via LaTeX (.pdf)_, or go to _File->Print preview_ and \"print\" the web page as a pdf file.\n",
    "\n",
    "* If relevant, hand-written calculations and drawings can be submitted alongside the notebook/pdf printout. Please scan/take a picture of your hand-written solutions and upload them in pdf, jpg or png format alongside the notebook. If you use this option, you need to **clearly mark in the notebook** that part of the solution is attached as a separate file and provide a reference to that file.  \n",
    "\n",
    "* Apart from the exception mentioned above, the notebook should be self-contained and executable. Standard packages and the `tssltools` module that is **distributed along with the exam** may be imported. This module contains **all the auxiliary code that you have used in the labs**, i.e. from the `tssltools_lab#` files, regardless of whether or not these functions/classes are relevant for solving the exam. The `tssltools` module also contains some additional code that can come in handy (in that case, the relevant code is referred to in the problem formulation).\n",
    "If you rely on external code that you have written (e.g. when solving the lab assignments in the course) it should be copied in to the notebook.\n",
    "\n",
    "* **Responsible teacher:** Fredrik Lindsten, available over email (fredrik.lindsten@liu.se) or phone (070 085 07 90) during the exam.  \n",
    "\n",
    "\n",
    "### Grades\n",
    "The maximum number of points is 40 (8+13+12+7 for the four problems, respectively). The _tentative_ levels for the grades (A-F) are:\n",
    "- A=37-40 points\n",
    "- B=33-36 points\n",
    "- C=23-32 points\n",
    "- D=19-22 points\n",
    "- E=15-18 points\n",
    "- F=0-14 points (fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  # Loading data / handling data frames\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default figure size for plots.\n",
    "# Feel free to change this if the suggested setting results in too small/large plots on your machine!\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1:\n",
    "(9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** The file `data_problem1.csv` contains a sequence of observations. In this problem you should do the following:\n",
    "\n",
    "1. Load the data and split it into 80 % training and 20 % validation data.\n",
    "2. Pre-process the data as you find appropriate.\n",
    "3. Produce mean-squared-error curves for model orders in the range $p=1,\\dots,10$. Plot both training and validation errors as two separate curves.\n",
    "4. Based on the error curves, pick a final model order $p$ that you think is appropriate. Motivate your choice!\n",
    "\n",
    "_Hint:_ You can use the functions `fit_ar` and `predict_ar_1step` from lab 1 (also available in `tssltools`).  \n",
    "\n",
    "<div style=\"text-align: right\"> (6p) </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pandas.read_csv('data_problem1.csv',header=0)\n",
    "y0 = data['Data'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Verify that the resulting AR model is stable _directly based on the model parameters_ (i.e. you should not simulate the model for the verification).\n",
    "\n",
    "_Hint:_ You can use `np.linalg.eigvals` to solve this problem.\n",
    "\n",
    "<div style=\"text-align: right\"> (3p) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2:\n",
    "(12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** In this problem we will study a **structural time series** model.\n",
    "$$\n",
    "    \\begin{cases} \\alpha_t = T \\alpha_{t-1} + R \\eta_t, & \\eta_t \\sim \\mathcal{N}(0,Q), \\\\ y_t = Z \\alpha_t + \\varepsilon_t, & \\varepsilon_t \\sim \\mathcal{N}(0,H), \\end{cases}\n",
    "$$\n",
    "where $\\alpha_t$ contains a trend and seasonal part.\n",
    "The trend in this model is **quadratic** but the seasonality is unknown.\n",
    "\n",
    "The data file `data_problem2.csv` contains a sequence of observations from this model. Using this data you are tasked to do the following:\n",
    "\n",
    "1. Look at the provided data and find the seasonality $s$.\n",
    "2. Setup the complete model by writing down the matrices $T$, $R$, $Q$, $Z$, and $H$. Also specify your hidden states $\\alpha_t$. Remember to motivate your choices of matrices.\n",
    "3. Implement the Kalman filter and run it on the data to find the trend and seasonal component. Let the observation variance be 1. Set the seasonal and trend variance in the model to $0.01^2$. Set the mean of the initial state to 0 and the initial variance to the identity matrix multiplied by 10.\n",
    "4. Plot the resulting seasonal and trend component from the kalman filter.\n",
    "\n",
    "_Hint:_ The `LGSS` and `kfs_res` classes used in Lab 2 are available in the `tssltools` module.\n",
    "\n",
    "<div style=\"text-align: right\"> (9p) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Often we are in the situation of missing data. In this task you will study the difference between the smoothing and filtering distributions when working with missing data. You should do the following:\n",
    "\n",
    "1. Remove the data between index 20 and 60 from the data by setting those values to `np.nan`\n",
    "2. Run the Kalman filter on this new data.\n",
    "3. Run the Kalman smoother on the same data. The algorithm `kalman_smoother` is provided in `tssltools`\n",
    "4. Plot the data, the filtered mean $Z \\hat\\alpha_{t|t}$ and and the smooted mean $Z \\hat\\alpha_{t|n}$ in the same figure.\n",
    "5. Comment on the results\n",
    "\n",
    "<div style=\"text-align: right\"> (3p) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3:\n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data_problem3.csv` contains a sequence of observations. We will model this sequence using the following non-linear state space model,\n",
    "$$\n",
    "    \\begin{cases} \\alpha_{t+1} = 2 \\sin(\\alpha_{t}) + \\sigma_{\\eta} \\eta_t, & \\eta_t \\sim \\mathcal{N}(0,1) \\\\\n",
    "    y_t = \\frac{\\alpha_t^2}{2} + \\sigma_{\\varepsilon} \\varepsilon_t & \\varepsilon_t \\sim \\mathcal{N}(0,1).\n",
    "    \\end{cases}\n",
    "$$\n",
    "with initial distribution $\\alpha_1 \\sim \\mathcal{N}(0,\\sigma_{\\eta}^{2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** To implement a bootstrap particle filter we need to perform three operations, propagation, weighting, and resampling. In this problem you should do the following:\n",
    "\n",
    "1. Find the conditional distribution of $y_t \\mid \\alpha_t$.\n",
    "2. Implement a function that takes $N$ particles $\\alpha_t^i$ and propagates them to $\\alpha_{t+1}^i$.\n",
    "3. Implement a function that takes $N$ particles $\\alpha_t^i$ and an observation $y_t$ and calculates the log-weights $\\log \\omega_t^i$.\n",
    "\n",
    "<div style=\"text-align: right\"> (5p) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** using the functions from the previous part implement a **Bootstrap Particle Filter** that runs on the data. You should solve the following parts:\n",
    "\n",
    "1. Set the parameters $\\sigma_{\\eta} = 0.3$ and $\\sigma_{\\varepsilon} = 0.5$\n",
    "2. Use the bootstrap particle filter to calculate the filtered mean of $\\sin(\\alpha_t)^2$. _(Note the square)_\n",
    "3. Provide a plot of your estimate.\n",
    "\n",
    "Use $N = 200$ particles when performing your estimate.\n",
    "\n",
    "If you failed to do the first part you can use the functions `propagate_wrong` and `logweight_fun_wrong` from the `tssltools` module to implement and run your bootstrap particle filter.\n",
    "\n",
    "<div style=\"text-align: right\"> (5p) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4:\n",
    "(9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Consider the problem of one-step-ahead prediction for a time series $\\{y_t\\}_{t\\geq 1}$. The code cell below defines a two-layer Jordan-Elman RNN for solving this problem. Write out the mathematical expressions corresponding to this model, in terms of the hidden state variables, the state update equations, and the output equations. Also, for all parameters in your model, specify their respective dimensions.\n",
    "\n",
    "<div style=\"text-align: right\"> (4p) </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, None, 30)          960       \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 20)          1020      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 100)         2100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           101       \n",
      "=================================================================\n",
      "Total params: 4,181\n",
      "Trainable params: 4,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model=keras.Sequential([\n",
    "    layers.SimpleRNN(units = 30, input_shape=(None,1), return_sequences=True, activation='tanh'),\n",
    "    layers.SimpleRNN(units = 20, input_shape=(None,1), return_sequences=True, activation='tanh'),\n",
    "    layers.Dense(units = 100, activation='relu'),\n",
    "    layers.Dense(units = 1, activation='linear')\n",
    "])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Together with your collaborator you face the problem of fitting an RNN model for an observed time series consisting of 50,000 observations, $\\{y_t\\}_{t=1}^{50000}$. For computational reasons, your collaborator has concluded that you can only afford to process 100 observations per gradient update when training the model. The following generator function has been written for this purpose, which will be passed to the Keras training procedure (`model.fit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train(window_size=100):    \n",
    "    # ntrain = number of training data points\n",
    "    while True:        \n",
    "        start_of_window = np.random.randint(0, ntrain - window_size)  # First time index of window (inclusive)\n",
    "        end_of_window = start_of_window + window_size  # Last time index of window (exclusive, i.e. this is really the first index _after_ the window)\n",
    "        yield x_train[:,start_of_window:end_of_window,:], y_train[:,start_of_window:end_of_window,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what the the generator function does, either using words or a mathematical expression.\n",
    "\n",
    "<div style=\"text-align: right\"> (1p) </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Continuing the question from part b). When evaluating the fitted model you are not very happy with the results. After careful investigations you conclude that there are very long ranging dependencies in this time seris, much longer than 100 time steps. You collaborator mentions that _stateful training_ might be a good idea in such situations, but can't remember exactly what it means. Explain (using a couple of sentences) what stateful training is and how/why it can be useful in this situation.\n",
    "\n",
    "<div style=\"text-align: right\"> (2p) </div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Continuing the question from part c). Is there a problem with using stateful training (i.e. simply setting `stateful=True` in the RNN model definition) when using the generator from part a)? Explain briefly why/why not.\n",
    "\n",
    "<div style=\"text-align: right\"> (2p) </div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
