{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification Laboration\n",
    "\n",
    "\n",
    "Images used in this laboration are from CIFAR 10 (https://en.wikipedia.org/wiki/CIFAR-10). The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. Your task is to make a classifier, using a convolutional neural network, that can correctly classify each image into the correct class.\n",
    "\n",
    "You need to answer all questions in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What is a convolution\n",
    "\n",
    "To understand a bit more about convolutions, we will first test the convolution function in scipy using a number of classical filters. \n",
    "\n",
    "Convolve the image with Gaussian filter, a Sobel X filter, and a Sobel Y filter, using the function 'convolve2d' in 'signal' from scipy.\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html\n",
    "\n",
    "In a CNN, many filters are applied in each layer, and the filter coefficients are learned through back propagation (which is in contrast to traditional image processing, where the filters are designed by an expert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is finished\n",
    "\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "# Get a test image\n",
    "from scipy import misc\n",
    "image = misc.ascent()\n",
    "\n",
    "# Define a help function for creating a Gaussian filter\n",
    "def matlab_style_gauss2D(shape=(3,3),sigma=0.5):\n",
    "    \"\"\"\n",
    "    2D gaussian mask - should give the same result as MATLAB's\n",
    "    fspecial('gaussian',[shape],[sigma])\n",
    "    \"\"\"\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "# Create Gaussian filter with certain size and standard deviation\n",
    "gaussFilter = matlab_style_gauss2D((15,15),4)\n",
    "\n",
    "# Define filter kernels for SobelX and Sobely\n",
    "sobelX = np.array([[ 1, 0,  -1],\n",
    "                    [2, 0, -2],\n",
    "                    [1, 0, -1]]) \n",
    "\n",
    "sobelY = np.array([[ 1, 2,  1],\n",
    "                    [0, 0, 0],\n",
    "                    [-1, -2, -1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution using the function 'convolve2d' for the different filters\n",
    "filterResponseGauss = signal.convolve2d(image,gaussFilter)\n",
    "filterResponseSobelX = signal.convolve2d(image,sobelX)\n",
    "filterResponseSobelY = signal.convolve2d(image,sobelY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show filter responses\n",
    "fig, (ax_orig, ax_filt1, ax_filt2, ax_filt3) = plt.subplots(1, 4, figsize=(20, 6))\n",
    "ax_orig.imshow(image, cmap='gray')\n",
    "ax_orig.set_title('Original')\n",
    "ax_orig.set_axis_off()\n",
    "ax_filt1.imshow(np.absolute(filterResponseGauss), cmap='gray')\n",
    "ax_filt1.set_title('Filter response')\n",
    "ax_filt1.set_axis_off()\n",
    "ax_filt2.imshow(np.absolute(filterResponseSobelX), cmap='gray')\n",
    "ax_filt2.set_title('Filter response')\n",
    "ax_filt2.set_axis_off()\n",
    "ax_filt3.imshow(np.absolute(filterResponseSobelY), cmap='gray')\n",
    "ax_filt3.set_title('Filter response')\n",
    "ax_filt3.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Understanding convolutions\n",
    "\n",
    "Question 1: What do the 3 different filters (Gaussian, SobelX, SobelY) do to the original image?\n",
    "    \n",
    "    The Gaussian filters remove the Gaussian noise and blur the image.\n",
    "    The SobelX filters keep the vertical features of the image.\n",
    "    The SobelY filters keep the horitical features of the image.\n",
    "\n",
    "Question 2: What is the size of the original image? How many channels does it have? How many channels does a color image normally have?\n",
    "    \n",
    "    The size of original image is 512 * 512, and there is 1 channel. A color image normally have 3 channels.\n",
    "    \n",
    "Question 3: What is the size of the different filters?\n",
    "\n",
    "    The guassian filter is 15x15. The two others(SobelX and SobelY) are 3x3.\n",
    "    \n",
    "Question 4: What is the size of the filter response if mode 'same' is used for the convolution ?\n",
    "\n",
    "    The size of the filter respone is 512 x 512 if mode 'same' is used.\n",
    "\n",
    "Question 5: What is the size of the filter response if mode 'valid' is used for the convolution? How does the size of the valid filter response depend on the size of the filter? \n",
    "\n",
    "    http://www.uml.org.cn/ai/201909102.asp\n",
    "    \n",
    "    The size of the filter respone is (512 - size of filter + 1) x (512 - size of filter + 1) if mode 'vaild' is used.\n",
    "\n",
    "Question 6: Why are 'valid' convolutions a problem for CNNs with many layers?\n",
    "\n",
    "    http://www.uml.org.cn/ai/201909102.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for checking sizes of image and filter responses\n",
    "\n",
    "print(\"Sizes of image : {}\".format(image.shape))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Sizes of Gaussian filters respone if mode is 'same' : {}\".format((signal.convolve2d(image,gaussFilter,mode='same')).shape))\n",
    "print(\"Sizes of SobelX filter respone if mode is 'same' : {}\".format((signal.convolve2d(image,sobelX,mode='same')).shape))\n",
    "print(\"Sizes of SobelY filter respone if mode is 'same' : {}\".format((signal.convolve2d(image,sobelY,mode='same')).shape))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Sizes of Gaussian filters respone if mode is 'valid' : {}\".format((signal.convolve2d(image,gaussFilter,mode='valid')).shape))\n",
    "print(\"Sizes of SobelX filter respone if mode is 'valid' : {}\".format((signal.convolve2d(image,sobelX,mode='valid')).shape))\n",
    "print(\"Sizes of SobelY filter respone if mode is 'valid' : {}\".format((signal.convolve2d(image,sobelY,mode='valid')).shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 3: Get a graphics card\n",
    "\n",
    "Skip this part if you run on a CPU\n",
    "\n",
    "Let's make sure that our script can see the graphics card that will be used. The graphics cards will perform all the time consuming convolutions in every training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 4: How fast is the graphics card?\n",
    "\n",
    "Question 7: Why are the filters of size 7 x 7 x 3, and not 7 x 7 ? \n",
    "\n",
    "    Because usually a color picture has 3 channels, each channel means one kind of original color(RGB). When the filter is processing the picture, it should process all the channel of a picture, so it is 7 x 7 x3\n",
    "\n",
    "Question 8: What operation is performed by the 'Conv2D' layer? Is it a standard 2D convolution, as performed by the function signal.convolve2d we just tested?\n",
    "\n",
    "    The operation performed by the 'Conv2D' layer is an element-wise (or point-wise) multiplication.\n",
    "    \n",
    "    The function signal.convolve2d we just tested was not not a standard 2D convolution, because it only contains one layers, but a standard 2D convolution contains many layers.\n",
    "\n",
    "Lets investigate how much faster a convolution is with the graphics card (skip this part if you run on a CPU)\n",
    "\n",
    "Question 9: How much faster is the graphics card, compared to the CPU, for convolving a batch of 100 images?\n",
    "\n",
    "    CPU (s):\n",
    "    1.3436729000000014\n",
    "    GPU (s):\n",
    "    0.04617600000000266\n",
    "    GPU speedup over CPU: 29x\n",
    "    \n",
    "Question 10: How much faster is the graphics card, compared to the CPU, for convolving a batch of 2 images? Explain the difference compared to 100 images.\n",
    "\n",
    "    CPU (s):\n",
    "    0.05910560000120313\n",
    "    GPU (s):\n",
    "    0.0339934000003268\n",
    "    GPU speedup over CPU: 1x\n",
    "    \n",
    "    The difference compared to 100 images is that the time used by CPU is closed to the GPU's. It is because that the input data is small.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to compare processing time of CPU and GPU\n",
    "\n",
    "import timeit\n",
    "\n",
    "n_images_in_batch = 100\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "# Perform convolutions using the CPU\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_images = tf.random.normal((n_images_in_batch, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_images)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "# Perform convolutions using the GPU (graphics card)\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_images = tf.random.normal((n_images_in_batch, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_images)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the convolution several times and measure the time\n",
    "print('Time (s) to convolve 32 filters of size 7 x 7 x 3 over 100 random images of size 100 x 100 x 3'\n",
    "      ' (batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 5:  Load data\n",
    "Time to make a 2D CNN. Load the images and labels from keras.datasets, this cell is already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Download CIFAR train and test data\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = cifar10.load_data()\n",
    "\n",
    "print(\"Training images have size {} and labels have size {} \".format(Xtrain.shape, Ytrain.shape))\n",
    "print(\"Test images have size {} and labels have size {} \\n \".format(Xtest.shape, Ytest.shape))\n",
    "\n",
    "# Reduce the number of images for training and testing to 10000 and 2000 respectively, \n",
    "# to reduce processing time for this laboration\n",
    "Xtrain = Xtrain[0:10000]\n",
    "Ytrain = Ytrain[0:10000]\n",
    "\n",
    "Xtest = Xtest[0:2000]\n",
    "Ytest = Ytest[0:2000]\n",
    "\n",
    "Ytestint = Ytest\n",
    "\n",
    "print(\"Reduced training images have size %s and labels have size %s \" % (Xtrain.shape, Ytrain.shape))\n",
    "print(\"Reduced test images have size %s and labels have size %s \\n\" % (Xtest.shape, Ytest.shape))\n",
    "\n",
    "# Check that we have some training examples from each class\n",
    "for i in range(10):\n",
    "    print(\"Number of training examples for class {} is {}\" .format(i,np.sum(Ytrain == i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 6: Plotting\n",
    "\n",
    "Lets look at some of the training examples, this cell is already finished. You will see different examples every time you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(18):\n",
    "    idx = np.random.randint(7500)\n",
    "    label = Ytrain[idx,0]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(Xtrain[idx])\n",
    "    plt.title(\"Class: {} ({})\".format(label, classes[label]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Part 7: Split data into training, validation and testing\n",
    "Split your training data into training (Xtrain, Ytrain) and validation (Xval, Yval), so that we have training, validation and test datasets (as in the previous laboration). We use a function in scikit learn. Use 25% of the data for validation.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xval,Ytrain,Yval = train_test_split(Xtrain,Ytrain, test_size=0.25, train_size=0.75, random_state=123, shuffle=True, stratify=None)\n",
    "\n",
    "\n",
    "# Print the size of training data, validation data and test data\n",
    "print(\"Size of training data: {} and {}\".format(Xtrain.shape,Ytrain.shape))\n",
    "print(\"Size of validation data: {} and {}\".format(Xval.shape,Yval.shape))\n",
    "print(\"Size of test data: {} and {}\".format(Xtest.shape,Ytest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 8: Preprocessing of images\n",
    "\n",
    "Lets perform some preprocessing. The images are stored as uint8, i.e. 8 bit unsigned integers, but need to be converted to 32 bit floats. We also make sure that the range is -1 to 1, instead of 0 - 255. This cell is already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype for Xtrain, Xval, Xtest, to float32\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xval = Xval.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "\n",
    "# Change range of pixel values to [-1,1]\n",
    "Xtrain = Xtrain / 127.5 - 1\n",
    "Xval = Xval / 127.5 - 1\n",
    "Xtest = Xtest / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 9: Preprocessing of labels\n",
    "\n",
    "The labels (Y) need to be converted from e.g. '4' to \"hot encoded\", i.e. to a vector of type [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] . We use a function in Keras, see https://keras.io/api/utils/python_utils/#to_categorical-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Print shapes before converting the labels\n",
    "\n",
    "print(\"Shapes of labels:{},{},{}\".format(Ytrain.shape,Yval.shape,Ytest.shape))\n",
    "\n",
    "# Your code for converting Ytrain, Yval, Ytest to categorical\n",
    "\n",
    "Ytrain = to_categorical(Ytrain, num_classes=10)\n",
    "Yval = to_categorical(Yval, num_classes=10)\n",
    "Ytest = to_categorical(Ytest, num_classes=10)\n",
    "\n",
    "# Print shapes after converting the labels\n",
    "\n",
    "print(\"Shapes of labels:{},{},{}\".format(Ytrain.shape,Yval.shape,Ytest.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 10: 2D CNN\n",
    "Finish this code to create the image classifier, using a 2D CNN. Each convolutional layer will contain 2D convolution, batch normalization and max pooling. After the convolutional layers comes a flatten layer and a number of intermediate dense layers. The convolutional layers should take the number of filters as an argument, use a kernel size of 3 x 3, 'same' padding, and relu activation functions. The number of filters will double with each convolutional layer. The max pooling layers should have a pool size of 2 x 2. The intermediate dense layers before the final dense layer should take the number of nodes as an argument, use relu activation functions, and be followed by batch normalization. The final dense layer should have 10 nodes (= the number of classes in this laboration) and 'softmax' activation. Here we start with the Adam optimizer.\n",
    "\n",
    "Relevant functions are\n",
    "\n",
    "`model.add()`, adds a layer to the network\n",
    "\n",
    "`Dense()`, a dense network layer\n",
    "\n",
    "`Conv2D()`, performs 2D convolutions with a number of filters with a certain size (e.g. 3 x 3). \n",
    "\n",
    "`BatchNormalization()`, perform batch normalization\n",
    "\n",
    "`MaxPooling2D()`, saves the max for a given pool size, results in down sampling\n",
    "\n",
    "`Flatten()`, flatten a multi-channel tensor into a long vector\n",
    "\n",
    "`model.compile()`, compile the model, add \" metrics=['accuracy'] \" to print the classification accuracy during the training\n",
    "\n",
    "See https://keras.io/api/layers/core_layers/dense/ and https://keras.io/api/layers/reshaping_layers/flatten/ for information on how the `Dense()` and `Flatten()` functions work\n",
    "\n",
    "See https://keras.io/layers/convolutional/ for information on how `Conv2D()` works\n",
    "\n",
    "See https://keras.io/layers/pooling/ for information on how `MaxPooling2D()` works\n",
    "\n",
    "Import a relevant cost function for multi-class classification from keras.losses (https://keras.io/losses/)\n",
    "\n",
    "See the following links for how to compile, train and evaluate the model\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#compile-method\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#fit-method\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#evaluate-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "# Set seed from random number generator, for better comparisons\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "\n",
    "def build_CNN(input_shape, n_conv_layers=2, n_filters=16, n_dense_layers=0, n_nodes=50, use_dropout=False, learning_rate=0.01):\n",
    "\n",
    "    # Setup a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add first convolutional layer to the model, requires input shape\n",
    "    model.add(Conv2D(n_filters, (3, 3), strides = (1, 1), activation='relu',padding=\"same\",input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Add remaining convolutional layers to the model, the number of filters should increase a factor 2 for each layer\n",
    "    for i in range(n_conv_layers-1):\n",
    "        model.add(Conv2D(n_filters*(i+2), (3, 3), strides = (1, 1),activation='relu',padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "    # Add flatten layer\n",
    "    model.add(Flatten())\n",
    "    # Add intermediate dense layers\n",
    "    for i in range(n_dense_layers):\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        if use_dropout==True:\n",
    "            model.add(Dropout(rate=0.5))\n",
    "            \n",
    "    # Add final dense layer\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a help function for plotting the training results\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_results(history):\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    acc = history.history['accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.legend(['Training','Validation'])\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.legend(['Training','Validation'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Train 2D CNN\n",
    "\n",
    "Time to train the 2D CNN, start with 2 convolutional layers, no intermediate dense layers, learning rate = 0.01. The first convolutional layer should have 16 filters (which means that the second convolutional layer will have 32 filters).\n",
    "\n",
    "Relevant functions\n",
    "\n",
    "`build_CNN`, the function we defined in Part 10, call it with the parameters you want to use\n",
    "\n",
    "`model.fit()`, train the model with some training data\n",
    "\n",
    "`model.evaluate()`, apply the trained model to some test data\n",
    "\n",
    "See the following links for how to train and evaluate the model\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#fit-method\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#evaluate-method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 convolutional layers, no intermediate dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "\n",
    "# Build model\n",
    "model1 = build_CNN(input_shape, n_conv_layers=2, n_filters=16, n_dense_layers=0, n_nodes=50, use_dropout=False, learning_rate=0.01)\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history1 = model1.fit(x=Xtrain,y=Ytrain,epochs=epochs,batch_size=batch_size,validation_data=(Xval,Yval))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = model1.evaluate(x=Xtest,  y=Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Improving performance\n",
    "\n",
    "Skip question 12 if you run on a CPU\n",
    "\n",
    "Write down the test accuracy, are you satisfied with the classifier performance (random chance is 10%) ? \n",
    "\n",
    "    Test accuracy: 0.5675.\n",
    "    \n",
    "    We are not satisfied with the classifier performance.\n",
    "\n",
    "Question 11: How big is the difference between training and test accuracy?\n",
    "\n",
    "    There is about 50% gap between between training and test accuracy\n",
    "\n",
    "Question 12: How busy is the GPU for a batch size of 100? How much GPU memory is used? Hint: run 'watch nvidia-smi' on the cloud computer during training. \n",
    "    \n",
    "    The usage of the GPU is 2.1% (For RTX 2070).\n",
    "    It used 0.9487648 mb GPU memory. \n",
    "\n",
    "Question 13: For the DNN laboration we used a batch size of 10,000, why do we need to use a smaller batch size in this laboration?\n",
    "\n",
    "    In this lab, the size of the training data is 10,000, if the batch size is 10,000, each epoch of training is only 1 times, which means the model cannot leaning the feature correctly.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 convolutional layers, 1 intermediate dense layer (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Build model\n",
    "model2 = build_CNN(input_shape, n_conv_layers=2, n_filters=16, n_dense_layers=1, n_nodes=50, use_dropout=False, learning_rate=0.01)\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history2 = model2.fit(x=Xtrain,y=Ytrain,epochs=epochs,batch_size=batch_size,validation_data=(Xval,Yval))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = model2.evaluate(x=Xtest,  y=Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 convolutional layers, 1 intermediate dense layer (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Build model\n",
    "model3 = build_CNN(input_shape, n_conv_layers=4, n_filters=16, n_dense_layers=1, n_nodes=50, use_dropout=False, learning_rate=0.01)\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history3 = model3.fit(x=Xtrain,y=Ytrain,epochs=epochs,batch_size=batch_size,validation_data=(Xval,Yval))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = model3.evaluate(x=Xtest,  y=Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 13: Plot the CNN architecture\n",
    "\n",
    "To understand your network better, print the architecture using `model.summary()`\n",
    "\n",
    "Question 14: How many trainable parameters does your network have? Which part of the network contains most of the parameters?\n",
    "\n",
    "    There are 64,090 trainable parameters in the network.\n",
    "    The conv2d_29 (Conv2D) part contains most of the parameters.\n",
    "\n",
    "Question 15: What is the input to and output of a Conv2D layer? What are the dimensions of the input and output? \n",
    "\n",
    "    The input to a Conv2D layer is a multiple dimension matrix, and dimensions of the it are 4\n",
    "    The output to a Conv2D layer is a multiple dimension matrix, and dimensions of the it are 4\n",
    "\n",
    "Question 16: Is the batch size always the first dimension of each 4D tensor? Check the documentation for Conv2D, https://keras.io/layers/convolutional/\n",
    "    \n",
    "    Yes\n",
    "\n",
    "Question 17: If a convolutional layer that contains 128 filters is applied to an input with 32 channels, what is the number of channels in the output?\n",
    "\n",
    "    32.\n",
    "\n",
    "Question 18: Why is the number of parameters in each Conv2D layer *not* equal to the number of filters times the number of filter coefficients per filter (plus biases)?\n",
    "\n",
    "    number_parameters = out_channels * (in_channels * kernel_h * kernel_w + bias) \n",
    "\n",
    "Question 19: How does MaxPooling help in reducing the number of parameters to train?\n",
    "\n",
    "    It accumulate features from maps generated by convolving a filter over an image.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print network architecture\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 14: Dropout regularization\n",
    "\n",
    "Add dropout regularization to each intermediate dense layer, dropout probability 50%.\n",
    "\n",
    "Question 20: How much did the test accuracy improve with dropout, compared to without dropout?\n",
    "\n",
    "    The test accuracy improved 5%.\n",
    "\n",
    "Question 21: What other types of regularization can be applied? How can you add L2 regularization for the convolutional layers?\n",
    "    \n",
    "    L1(lasso), L2(ridge) and elastic net(L1 + L2)\n",
    "    Conv2D(kernel_regularizer = keras.regularizer.l2(0.01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 convolutional layers, 1 intermediate dense layer (50 nodes), dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Build model\n",
    "model4 = build_CNN(input_shape, n_conv_layers=4, n_filters=16, n_dense_layers=1, n_nodes=50, use_dropout=True, learning_rate=0.01)\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history4 = model4.fit(x=Xtrain,y=Ytrain,epochs=epochs,batch_size=batch_size,validation_data=(Xval,Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = model4.evaluate(x=Xtest,  y=Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 15: Tweaking performance\n",
    "\n",
    "You have now seen the basic building blocks of a 2D CNN. To further improve performance involves changing the number of convolutional layers, the number of filters per layer, the number of intermediate dense layers, the number of nodes in the intermediate dense layers, batch size, learning rate, number of epochs, etc. Spend some time (30 - 90 minutes) testing different settings.\n",
    "\n",
    "Question 22: How high test accuracy can you obtain? What is your best configuration?\n",
    "\n",
    "    The high test accuracy we obtained is 64.5%.\n",
    "    \n",
    "    batch_size = 100\n",
    "    epochs = 20\n",
    "    input_shape = (32, 32, 3)\n",
    "    n_conv_layers=3,\n",
    "    n_filters=32,\n",
    "    n_dense_layers=1,\n",
    "    n_nodes=100,\n",
    "    use_dropout=True,\n",
    "    dropout_rate = 0.5,\n",
    "    learning_rate=0.01.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Build model\n",
    "model5 = build_CNN(input_shape, n_conv_layers=3, n_filters=32, n_dense_layers=1, n_nodes=100, use_dropout=True, learning_rate=0.01)\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history5 = model5.fit(x=Xtrain,y=Ytrain,epochs=epochs,batch_size=batch_size,validation_data=(Xval,Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = model5.evaluate(x=Xtest,  y=Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 16: Rotate the test images\n",
    "\n",
    "How high is the test accuracy if we rotate the test images? In other words, how good is the CNN at generalizing to rotated images?\n",
    "\n",
    "Rotate each test image 90 degrees, the cells are already finished.\n",
    "\n",
    "Question 23: What is the test accuracy for rotated test images, compared to test images without rotation? Explain the difference in accuracy.\n",
    "\n",
    "    The test accuracy for rotated test images: 22.90%\n",
    "    The test accuracy for test images without rotation: 64.5%\n",
    "    \n",
    "    The rotated images have quiet different features compared with the original one, and the model can't analyied it. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myrotate(images):\n",
    "\n",
    "    images_rot = np.rot90(images, axes=(1,2))\n",
    "    \n",
    "    return images_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the test images 90 degrees\n",
    "Xtest_rotated = myrotate(Xtest)\n",
    "\n",
    "# Look at some rotated images\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(500)\n",
    "    \n",
    "    plt.subplot(2,10,i+1)\n",
    "    plt.imshow(Xtest[idx]/2+0.5)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2,10,i+11)\n",
    "    plt.imshow(Xtest_rotated[idx]/2+0.5)\n",
    "    plt.title(\"Rotated\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on rotated test set\n",
    "score = model4.evaluate(x=Xtest_rotated,  y=Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 17: Augmentation using Keras `ImageDataGenerator`\n",
    "\n",
    "We can increase the number of training images through data augmentation (we now ignore that CIFAR10 actually has 60 000 training images). Image augmentation is about creating similar images, by performing operations such as rotation, scaling, elastic deformations and flipping of existing images. This will prevent overfitting, especially if all the training images are in a certain orientation.\n",
    "\n",
    "We will perform the augmentation on the fly, using a built-in function in Keras, called `ImageDataGenerator`\n",
    "\n",
    "See https://keras.io/preprocessing/image/ , the `flow` method should be used\n",
    "\n",
    "Do *NOT* use use_multiprocessing=True here, as it can cause strange errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 60 000 training images again. ImageDataGenerator manages validation data on its own\n",
    "(Xtrain, Ytrain), _ = cifar10.load_data()\n",
    "\n",
    "# Reduce number of images to 10,000\n",
    "Xtrain = Xtrain[0:10000]\n",
    "Ytrain = Ytrain[0:10000]\n",
    "\n",
    "# Change data type and rescale range\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xtrain = Xtrain / 127.5 - 1\n",
    "\n",
    "# Convert labels to hot encoding\n",
    "Ytrain = to_categorical(Ytrain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a data generator with on-the-fly data augmentation, 20% validation split\n",
    "# Use a rotation range of 30 degrees, horizontal and vertical flipping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=30, horizontal_flip = True, vertical_flip = True,validation_split=0.2)\n",
    "\n",
    "# Setup a flow for training data, assume that we can fit all images into CPU memory\n",
    "\n",
    "train_flow = datagen.flow(Xtrain, Ytrain, batch_size = 100, subset = 'training')\n",
    "\n",
    "# Setup a flow for validation data, assume that we can fit all images into CPU memory\n",
    "valid_flow = datagen.flow(Xtrain, Ytrain, batch_size = 100, subset = 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 18: What about big data?\n",
    "\n",
    "Question 24: How would you change the code for the image generator if you cannot fit all training images in CPU memory? What is the disadvantage of doing that change?\n",
    "\n",
    "    We could use the function \"flow_from_directory\", the disadvantage of doing that change is the processing time will be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some augmented images\n",
    "plot_datagen = datagen.flow(Xtrain, Ytrain, batch_size=1)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(18):\n",
    "    (im, label) = plot_datagen.next()\n",
    "    im = (im[0] + 1) * 127.5\n",
    "    im = im.astype('int')\n",
    "    label = np.flatnonzero(label)[0]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Class: {} ({})\".format(label, classes[label]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 19: Train the CNN with images from the generator\n",
    "\n",
    "See https://keras.io/api/models/model_training_apis/#fit-method for how to use model.fit with a generator instead of a fix dataset (numpy arrays)\n",
    "\n",
    "To make the comparison fair to training without augmentation\n",
    "\n",
    "    steps_per_epoch should be set to: len(Xtrain)*(1 - validation_split)/batch_size\n",
    "\n",
    "    validation_steps should be set to: len(Xtrain)*validation_split/batch_size\n",
    "\n",
    "Question 25: How quickly is the training accuracy increasing compared to without augmentation? Explain why there is a difference compared to without augmentation. What parameter is necessary to change to perform more training?\n",
    "\n",
    "    The training accuracy with augmentation is 35.35%\n",
    "    The training accuracy without augmentation is 20.15% \n",
    "    \n",
    "    The difference compared to without augmentation is that the model trained with more types of rotated images.\n",
    "    \n",
    "    The parameter of validation_split is necessary to change.\n",
    "\n",
    "Question 26: What other types of image augmentation can be applied, compared to what we use here?\n",
    "\n",
    "    zoom,scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 200\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Build model (your best config)\n",
    "model6 = build_CNN(input_shape, n_conv_layers=3, n_filters=32, n_dense_layers=1, n_nodes=100, use_dropout=True, learning_rate=0.01)\n",
    "    \n",
    "# Train the model using on the fly augmentation\n",
    "history6 = model6.fit(train_flow, steps_per_epoch = 80, epochs = epochs, validation_data = valid_flow, validation_steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is still a big difference in accuracy for original and rotated test images\n",
    "\n",
    "# Evaluate the trained model on original test set\n",
    "score = model6.evaluate(Xtest, Ytest, batch_size = batch_size, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "# Evaluate the trained model on rotated test set\n",
    "score = model6.evaluate(Xtest_rotated, Ytest, batch_size = batch_size, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 20: Plot misclassified images\n",
    "\n",
    "Lets plot some images where the CNN performed badly, these cells are already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified images\n",
    "y_pred = model6.predict_classes(Xtest)\n",
    "y_correct = np.argmax(Ytest,axis=-1)\n",
    "\n",
    "miss = np.flatnonzero(y_correct != y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few of them\n",
    "plt.figure(figsize=(15,4))\n",
    "perm = np.random.permutation(miss)\n",
    "for i in range(18):\n",
    "    im = (Xtest[perm[i]] + 1) * 127.5\n",
    "    im = im.astype('int')\n",
    "    label_correct = y_correct[perm[i]]\n",
    "    label_pred = y_pred[perm[i]]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"{}, classified as {}\".format(classes[label_correct], classes[label_pred]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 21: Testing on another size\n",
    "\n",
    "Question 27: This CNN has been trained on 32 x 32 images, can it be applied to images of another size? If not, why is this the case?\n",
    "\n",
    "    It cannot applied to images of another size. Because different size of images have different size in layers, so the weights cannot match.\n",
    "\n",
    "Question 28: Is it possible to design a CNN that can be trained on images of one size, and then applied to an image of any size? How?\n",
    "\n",
    "    It's possible.\n",
    "    \n",
    "    First tranform the image into specifical size of n x n, which can be trained by cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 22: Pre-trained 2D CNNs\n",
    "\n",
    "There are many deep 2D CNNs that have been pre-trained using the large ImageNet database (several million images, 1000 classes). Import a pre-trained ResNet50 network from Keras applications. Show the network using `model.summary()`\n",
    "\n",
    "Question 29: How many convolutional layers does ResNet50 have? \n",
    "\n",
    "Question 30: How many trainable parameters does the ResNet50 network have? \n",
    "\n",
    "Question 31: What is the size of the images that ResNet50 expects as input?\n",
    "\n",
    "Question 32: Using the answer to question 30, explain why the second derivative is seldom used when training deep networks.\n",
    "\n",
    "Apply the pre-trained CNN to 5 random color images that you download and copy to the cloud machine or your own computer. Are the predictions correct? How certain is the network of each image class?\n",
    "\n",
    "These pre-trained networks can be fine tuned to your specific data, and normally only the last layers need to be re-trained, but it will still be too time consuming to do in this laboration.\n",
    "\n",
    "See https://keras.io/api/applications/ and https://keras.io/api/applications/resnet/#resnet50-function \n",
    "\n",
    "Useful functions\n",
    "\n",
    "`image.load_img` in keras.preprocessing\n",
    "\n",
    "`image.img_to_array` in keras.preprocessing\n",
    "\n",
    "`ResNet50` in keras.applications.resnet50\n",
    "\n",
    "`preprocess_input` in keras.applications.resnet50\n",
    "\n",
    "`decode_predictions` in keras.applications.resnet50\n",
    "\n",
    "`expand_dims` in numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for using pre-trained ResNet 50 on 5 color images of your choice. \n",
    "# The preprocessing should transform the image to a size that is expected by the CNN.\n",
    "from keras.utils import get_file\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import expand_dims\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "image_path = ['https://www.google.com/url?sa=i&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSongbird&psig=AOvVaw18IgNppXLcCpCZU3MfWpja&ust=1619460182143000&source=images&cd=vfe&ved=2ahUKEwjPn6y4_ZnwAhUGC94KHRDKACMQjRx6BAgAEAc',\n",
    "              'https://www.google.com/url?sa=i&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDalmatian_(dog)&psig=AOvVaw1V-7w8A4cAL4kPNspQx5y2&ust=1619460233099000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCIiCztH9mfACFQAAAAAdAAAAABAE',\n",
    "              'https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.pinterest.se%2Fpin%2F743023638507864435%2F&psig=AOvVaw1AKbEZ6arfko7mrRBo6V-F&ust=1619460399074000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCMjG2aD-mfACFQAAAAAdAAAAABAE',\n",
    "              'https://www.google.com/url?sa=i&url=https%3A%2F%2Fsv.m.wikipedia.org%2Fwiki%2FFil%3AOpen_book_nae_02.svg&psig=AOvVaw38zYRFwZjRvroBOBM4KXCo&ust=1619460456992000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPCyo7z-mfACFQAAAAAdAAAAABAE',\n",
    "              'https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.landolakes.com%2Frecipe%2F16714%2Fbirthday-cake%2F&psig=AOvVaw3dsHC8_CMkhzHJclfsF83W&ust=1619460487317000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPDu4sr-mfACFQAAAAAdAAAAABAE']\n",
    "origi = ['songbird', 'Dalmatian dog', 'Sunflower', 'book', 'cake' ]\n",
    "label = ['a' for i in range(5)]\n",
    "z = 0\n",
    "for i in image_path:\n",
    "    image_url = get_file(\"aa\", origin=i )\n",
    "    image = load_img(image_url, target_size = (224, 224))\n",
    "    x = img_to_array(image)\n",
    "    x = expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x)\n",
    "    y = model7.predict(x)\n",
    "    label[z] = decode_predictions(y, top = 1)[0]\n",
    "    z += 1\n",
    "\n",
    "print('The predicti label is :', label)\n",
    "print('The label is : ', origi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import expand_dims\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#url = 'cat.jpg'\n",
    "url ='https://media.nature.com/lw800/magazine-assets/d41586-020-01430-5/d41586-020-01430-5_17977552.jpg'\n",
    "#url='https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.rover.com%2Fblog%2Funique-dog-names%2F&psig=AOvVaw2UL8hG82ymBRONOJ21zFs-&ust=1619642123016000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPDg6pyjn_ACFQAAAAAdAAAAABAU'\n",
    "image_url = get_file(\"123\", origin=url )\n",
    "image = load_img(image_url, target_size = (224, 224))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(get_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for using pre-trained ResNet 50 on 5 color images of your choice. \n",
    "# The preprocessing should transform the image to a size that is expected by the CNN.\n",
    "from keras.utils import get_file\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import expand_dims\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "model7 = ResNet50(weights = 'imagenet')\n",
    "model7.summary()\n",
    "\n",
    "image_path = ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Eopsaltria_australis_-_Mogo_Campground.jpg/1280px-Eopsaltria_australis_-_Mogo_Campground.jpg',\n",
    "              #'https://www.purina.com.au/-/media/project/purina/main/breeds/dog/dog_dalmatian_desktop.jpg?h=475&la=en&w=825&hash=82053FCC10EBEC77A3A64BC46B847DEE',\n",
    "              'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40flower_sky_backdrop.jpg/800px-Sunflower_sky_backdrop.jpg',\n",
    "              'https://novapublishers.com/wp-content/uploads/2019/07/manybooks.jpg',\n",
    "              'https://i.ytimg.com/vi/qtlhdIfojmc/maxresdefault.jpg']\n",
    "origi = ['songbird', 'Dalmatian dog', 'Sunflower', 'book', 'cake' ]\n",
    "label = ['a' for i in range(4)]\n",
    "z = 0\n",
    "for i in image_path:\n",
    "    #image_url = get_file(str('nnnn'+str(i) ), origin=i )\n",
    "    nm = str('image'+str(i+1))\n",
    "    image = load_img(get_file(nm), origin=i ), target_size = (224, 224))\n",
    "    x = img_to_array(image)\n",
    "    x = expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x)\n",
    "    y = model7.predict(x)\n",
    "    label[z] = decode_predictions(y, top = 1)[0]\n",
    "    z += 1\n",
    "\n",
    "print('The predicti label is :', label)\n",
    "print('The label is : ', origi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str('nn'+str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=image_path[0]\n",
    "image = load_img(get_file(\"nn1\", origin=i ), target_size = (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import expand_dims\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#url = 'cat.jpg'\n",
    "url =image_path[2] #'https://media.nature.com/lw800/magazine-assets/d41586-020-01430-5/d41586-020-01430-5_17977552.jpg'\n",
    "#url='https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.rover.com%2Fblog%2Funique-dog-names%2F&psig=AOvVaw2UL8hG82ymBRONOJ21zFs-&ust=1619642123016000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPDg6pyjn_ACFQAAAAAdAAAAABAU'\n",
    "image_url = get_file(\"homd\", origin=url )\n",
    "image = load_img(image_url, target_size = (224, 224))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "model7 = ResNet50(weights = 'imagenet')\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://upload.wikimedia.org/wikipedia/commons/thumb/4/40flower_sky_backdrop.jpg/800px-Sunflower_sky_backdrop.jpg\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://upload.wikimedia.org/wikipedia/commons/thumb/4/40flower_sky_backdrop.jpg/800px-Sunflower_sky_backdrop.jpg: 404 -- Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3518629cb32e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://upload.wikimedia.org/wikipedia/commons/thumb/4/40flower_sky_backdrop.jpg/800px-Sunflower_sky_backdrop.jpg: 404 -- Not Found"
     ]
    }
   ],
   "source": [
    "# Your code for using pre-trained ResNet 50 on 5 color images of your choice. \n",
    "# The preprocessing should transform the image to a size that is expected by the CNN.\n",
    "from keras.utils import get_file\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import expand_dims\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "image_path = ['https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Eopsaltria_australis_-_Mogo_Campground.jpg/1280px-Eopsaltria_australis_-_Mogo_Campground.jpg',\n",
    "              'https://upload.wikimedia.org/wikipedia/commons/a/af/Golden_retriever_eating_pigs_foot.jpg',\n",
    "              'https://upload.wikimedia.org/wikipedia/commons/thumb/4/40flower_sky_backdrop.jpg/800px-Sunflower_sky_backdrop.jpg',\n",
    "              'https://novapublishers.com/wp-content/uploads/2019/07/manybooks.jpg',\n",
    "              'https://i.ytimg.com/vi/qtlhdIfojmc/maxresdefault.jpg']\n",
    "origi = ['songbird', 'dog', 'Sunflower', 'book', 'cake' ]\n",
    "label = ['a' for i in range(5)]\n",
    "z = 0\n",
    "for i in range(0,len(image_path)):\n",
    "    image_url = get_file(origi[i], origin=image_path[i])\n",
    "    image = load_img(image_url, target_size = (224, 224))\n",
    "    x = img_to_array(image)\n",
    "    x = expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x)\n",
    "    y = model7.predict(x)\n",
    "    label[z] = decode_predictions(y, top = 1)[0]\n",
    "    z += 1\n",
    "\n",
    "print('The predicti label is :', label)\n",
    "print('The label is : ', origi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
